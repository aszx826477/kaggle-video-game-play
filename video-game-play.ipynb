{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file into dataframe\n",
    "train_df = pd.read_csv(\"train.csv\", parse_dates=[\"purchase_date\", \"release_date\"])\n",
    "test_df = pd.read_csv(\"test.csv\", parse_dates=[\"purchase_date\", \"release_date\"], index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1 Data processing\n",
    "* Do one-hot encoding for `tags`, `genres` and `categories` of trainning dataset and test dataset respectively. Then union the one-hot encoding of and drop duplicates of columns. \n",
    "* Split the date into year and month ignoring day. \n",
    "* Add a new feature *interval* = *purchase_date_day* - *release_date_day*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a feature of interval using purchase_date - release_date\n",
    "train_df[\"interval\"] = train_df[\"purchase_date\"].apply(lambda x: x.day) - train_df[\"release_date\"].apply(lambda x: x.day)\n",
    "\n",
    "def extract_date(df, column):\n",
    "    df[column + \"_year\"] = df[column].apply(lambda x: x.year)\n",
    "    df[column + \"_month\"] = df[column].apply(lambda x: x.month)\n",
    "\n",
    "extract_date(train_df, \"purchase_date\")\n",
    "extract_date(train_df, \"release_date\")\n",
    "\n",
    "train_df = train_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for trainning data\n",
    "tags_train = train_df[\"tags\"].str.get_dummies(\",\") # shape = (357, 312)\n",
    "genres_train = train_df[\"genres\"].str.get_dummies(\",\") # (357, 20)\n",
    "categories_train = train_df[\"categories\"].str.get_dummies(\",\") # (357, 29)\n",
    "\n",
    "diff = genres_train.columns.difference(tags_train.columns) # drop duplicates of columns\n",
    "train_one_hot = tags_train.join(genres_train[diff]) # (357, 312)\n",
    " \n",
    "diff = categories_train.columns.difference(train_one_hot.columns)\n",
    "train_one_hot = train_one_hot.join(categories_train[diff]) # (357, 340)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot endcoding for test data\n",
    "tags_test = test_df[\"tags\"].str.get_dummies(\",\") # (90, 229)\n",
    "genres_test = test_df[\"genres\"].str.get_dummies(\",\") # (90, 14)\n",
    "categories_test = test_df[\"categories\"].str.get_dummies(\",\") # (90, 28)\n",
    "\n",
    "diff = genres_test.columns.difference(tags_test.columns)\n",
    "test_one_hot = tags_test.join(genres_test[diff]) # (90, 229)\n",
    "\n",
    "diff = categories_test.columns.difference(test_one_hot.columns)\n",
    "test_one_hot = test_one_hot.join(categories_test[diff]) # (90, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union train_one_hot and test_one hot features\n",
    "# Fill the NaN with 0.0\n",
    "\n",
    "diff = test_one_hot.columns.difference(train_one_hot.columns) # (5,)\n",
    "train_one_hot = pd.concat([train_one_hot, pd.DataFrame(columns=list(diff))], axis=1) # (357, 345)\n",
    "train_one_hot = train_one_hot.fillna(0.0)\n",
    "\n",
    "diff = train_one_hot.columns.difference(test_one_hot.columns) # (89,)\n",
    "test_one_hot = pd.concat([test_one_hot, pd.DataFrame(columns=list(diff))], axis=1) # (90, 345)\n",
    "test_one_hot = test_one_hot.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2 Prepare data for trainning\n",
    "\n",
    "* `[X_train, y_train]` use to train a basic model\n",
    "* `[X_train_correct, y_train_corretc]` use to train a correction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full trainning dataset. \n",
    "# Use it to train and predict on test dataset at first.\n",
    "X_train = train_df.join(train_one_hot) \\\n",
    "                  .drop([\"genres\", \"tags\", \"categories\", \"purchase_date\", \"release_date\", \\\n",
    "                         \"id\", \"playtime_forever\"], axis = 1)\n",
    "y_train = train_df[\"playtime_forever\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sub-dataset (playtime_forever > 3) of the oringinal trainning set. \n",
    "# Use the sub-dataset to re-train a new model and then do prediction again to correct the outliers.\n",
    "train_df_correct = train_df[train_df[\"playtime_forever\"] > 3]\n",
    "X_train_correct = train_df_correct.join(train_one_hot) \\\n",
    "                                  .drop([\"genres\", \"tags\", \"categories\", \"purchase_date\",\"release_date\", \\\n",
    "                                         \"id\", \"playtime_forever\"], axis = 1)\n",
    "y_train_correct = train_df_correct[\"playtime_forever\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3 Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      presort=False, random_state=0, splitter='best')"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a decision tree regression model using full trainning dateset\n",
    "regDT = DecisionTreeRegressor(random_state=0)\n",
    "regDT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      presort=False, random_state=0, splitter='best')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a correction decision tree regression model using sub trainning dateset\n",
    "regDTCorrect = DecisionTreeRegressor(random_state=0)\n",
    "regDTCorrect.fit(X_train_correct, y_train_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n                      max_features='auto', max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, n_estimators=100,\n                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n                      warm_start=False)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a ramdom forest tree regression model using full trainning dataset\n",
    "regRF = RandomForestRegressor(max_depth=None, random_state=0, n_estimators=100)\n",
    "regRF.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 Predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test.csv again\n",
    "test_df = pd.read_csv(\"test.csv\", parse_dates=[\"purchase_date\", \"release_date\"], index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the test data\n",
    "test_df[\"interval\"] = test_df[\"purchase_date\"].apply(lambda x: x.day) - test_df[\"release_date\"].apply(lambda x: x.day)\n",
    "\n",
    "extract_date(test_df, \"purchase_date\")\n",
    "extract_date(test_df, \"release_date\")\n",
    "\n",
    "test_df = test_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the test data for prediction\n",
    "X_test = test_df.join(test_one_hot).drop([\"genres\", \"tags\", \"categories\", \"purchase_date\", \"release_date\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.        ,  0.63333333,  0.63333333,  0.        ,  0.1       ,\n        0.63333333,  0.03333333,  0.        ,  0.63333333,  4.21666667,\n        0.        ,  0.01666667,  0.        ,  0.1       ,  0.        ,\n        0.        ,  0.01666667,  1.26666667,  0.05      ,  0.63333333,\n        0.        ,  0.13333333,  0.96666667,  0.05      ,  0.        ,\n        0.        ,  0.63333333,  0.13333333,  1.68333333,  1.68333333,\n        1.68333333, 49.38333333,  2.3       ,  0.05      ,  4.21666667,\n        0.05      ,  0.        ,  0.        ,  0.        ,  2.5       ,\n        0.        ,  0.        ,  0.        ,  0.63333333,  0.        ,\n        0.        ,  0.96666667,  0.        ,  0.        ,  2.45      ,\n        0.        ,  0.        ,  4.33333333,  0.63333333,  0.63333333,\n        0.        ,  0.5       ,  0.        ,  0.01666667,  0.        ,\n        0.        ,  0.01666667,  0.63333333,  0.        ,  0.63333333,\n        0.2       ,  1.68333333,  4.51666667,  6.3       ,  0.63333333,\n        0.63333333, 92.63333333,  0.        , 49.38333333,  1.68333333,\n       92.63333333, 92.63333333,  0.        ,  0.63333333,  0.        ,\n        0.        ,  0.61666667,  0.        ,  0.        ,  9.01666667,\n        0.        ,  0.        ,  0.        ,  0.05      ,  0.        ])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  3.11666667,   6.36666667,   6.36666667,   6.36666667,\n         9.88333333,   3.06666667,   6.36666667,   3.11666667,\n         3.06666667,   6.36666667,   3.06666667,   3.06666667,\n         6.36666667,   3.16666667,   9.88333333,  28.98333333,\n         4.21666667,   4.55      ,   4.55      ,   3.11666667,\n         3.11666667,   6.36666667,   6.36666667,   4.55      ,\n         3.11666667,   3.11666667,   3.06666667,   4.55      ,\n         4.55      ,   6.36666667,  63.8       , 113.8       ,\n         4.55      ,   4.55      ,   3.16666667,   3.16666667,\n         6.36666667,  10.        ,   4.55      ,   3.06666667,\n         3.06666667,   3.11666667,   6.36666667,   4.21666667,\n         4.55      ,  20.56666667,  63.8       ,   4.21666667,\n         3.11666667,  31.98333333,  28.98333333,   3.11666667,\n         3.16666667,   3.06666667,   6.36666667,   4.21666667,\n         5.88333333,   6.36666667,  28.98333333,   6.36666667,\n         6.36666667,   4.21666667,   4.21666667,  20.61666667,\n         4.21666667,   5.88333333,  28.98333333,   4.21666667,\n         6.36666667,   3.06666667,   4.21666667, 113.8       ,\n         4.21666667, 113.8       ,   6.36666667, 113.8       ,\n       113.8       ,   3.08333333,   4.21666667,   5.11666667,\n         6.36666667,   4.18333333,   3.11666667,   9.88333333,\n         3.11666667,   3.11666667,   3.11666667,  63.8       ,\n        28.98333333,   6.36666667])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regDTCorrect.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.6075    ,  9.05633333,  0.59283333,  0.44283333,  5.47966667,\n        1.02783333,  2.53966667,  0.48116667,  1.49266667,  2.39583333,\n        1.871     ,  1.49583333,  9.027     ,  8.98783333,  9.0995    ,\n        2.33066667,  1.92133333,  1.83      ,  1.74116667,  9.33666667,\n        0.69783333,  6.40866667,  2.84316667,  0.46216667,  0.20533333,\n        1.95083333,  0.95466667,  1.00516667,  9.38366667,  2.52683333,\n        4.70283333, 27.89166667,  8.37833333,  0.9655    ,  2.47866667,\n        1.62483333,  4.17233333,  5.21016667,  2.30433333,  1.9535    ,\n        3.42633333,  1.68233333,  4.00233333,  2.394     ,  8.688     ,\n        1.75183333, 12.22083333,  0.75883333,  2.80733333, 14.18733333,\n        1.83083333,  1.97683333,  1.6875    ,  2.40983333,  1.20833333,\n        2.254     ,  2.39383333,  2.70683333,  1.28983333,  0.66016667,\n        1.887     ,  8.43683333,  1.03033333, 10.227     ,  7.80866667,\n        8.38283333,  0.98333333,  2.39733333, 10.4935    ,  0.45266667,\n        2.60166667, 14.52416667,  2.4435    , 29.09316667,  1.83016667,\n       17.45983333,  6.769     ,  3.89266667,  9.2895    ,  1.52183333,\n        0.89583333,  2.19983333,  1.34816667,  7.12866667,  4.49333333,\n        1.244     ,  1.364     ,  9.29916667,  0.63116667,  4.80916667])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regRF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 62, 64,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 62,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0, 64,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n        0,  0, 63,  0,  0])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_distance = regDTCorrect.predict(X_test) - regDT.predict(X_test) # calculate the correction distance\n",
    "filter = np.vectorize(lambda x: 0 if x < 30 else x) # filter the distance that < 30\n",
    "correct_vector = filter(correct_distance)\n",
    "correct_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 5 Generate submission csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First submission: desicion tree + correct vector\n",
    "y_test_predict = regDT.predict(X_test) + correct_vector\n",
    "result = pd.DataFrame({\"id\":range(90), \"playtime_forever\":y_test_predict})\n",
    "result.to_csv(\"submission_DT_correct.csv\", index=False)\n",
    "\n",
    "# Before add the correct vector, the DT model achieves 11+ score in public board.\n",
    "# After using correction, it can achieve 4+ score in public board.\n",
    "# However, the TA warned that the high performance in public board didn't mean the model also performed well in private board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second submission: random forest\n",
    "y_test_predict = regRF.predict(X_test)\n",
    "result = pd.DataFrame({\"id\":range(90), \"playtime_forever\":y_test_predict})\n",
    "result.to_csv(\"submission_RF.csv\", index=False)\n",
    "\n",
    "# The RF model gaines 15+ score in public board."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}